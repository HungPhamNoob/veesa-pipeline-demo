# ğŸ“ˆ Veesa Pipeline Demo (Functional Data Analysis with Explainable AI)

This repository is a **step-by-step demonstration** of the **VEESA pipeline** â€” a modern Explainable AI framework for *functional data analysis (FDA)* using **joint functional PCA (jfPCA)** and interpretable models such as **Random Forest** and **Neural Network**.

![R](https://img.shields.io/badge/R-4.3.2-blue?logo=r)

> ğŸ“„ Reference: [VEESA: Variability Extraction and Explainable Shape Analysis (Goode et al., 2025)](https://arxiv.org/abs/2501.07602)  
> ğŸ§© Original GitHub: [sandialabs/veesa](https://github.com/sandialabs/veesa)

---

## âš™ï¸ Project Overview

The project demonstrates how to:
1. **Simulate or import functional data** (e.g., spectroscopy, temporal signals).  
2. **Perform smoothing** and **alignment** using *Square-Root Velocity Function (SRVF)* representation.  
3. **Apply joint functional PCA (jfPCA)** to extract *amplitude* and *phase* variability.  
4. **Train interpretable ML models**:
   - ğŸŒ² Random Forest  
   - ğŸ§  Neural Network (Keras3 / TensorFlow backend)
5. **Compute feature importance (PFI)** and visualize **principal directions (efPCs)**.

---

## ğŸ§© Notebook Workflow

| Step | File | Description |
|------|------|-------------|
| 0 | `step_0.ipynb` | Data preparation and simulation setup |
| 1 | `step_1.ipynb` | Smoothing and alignment using SRVF |
| 2+3 | `step_2+3.ipynb` | Functional PCA (jfPCA) and feature extraction |
| 4 (1) | `step_4 (1).ipynb` | Random Forest model training |
| 4 (2) | `step_4 (2).ipynb` | Neural Network model training |
| 5+6 (1) | `step_5+6 (1).ipynb` | PFI + efPC visualization (Random Forest branch) |
| 5+6 (2) | `step_5+6 (2).ipynb` | PFI + efPC visualization (Neural Network branch) |

> ğŸ” **Recommendation:** Run this project in **Jupyter Notebook (R kernel)** for the best reproducibility and visualization experience.

---

## ğŸ§­ Core Libraries

| Category | Packages |
|-----------|-----------|
| **Functional Data Analysis** | `veesa`, `fdasrvf`, `tidyr`, `dplyr`, `purrr` |
| **Visualization** | `ggplot2`, `cowplot`, `patchwork` |
| **Machine Learning** | `randomForest`, `neuralnet`, `keras3`, `tensorflow` |
| **Pipeline & Utilities** | `reticulate`, `readr`, `base`, `stringr` |

---

## ğŸ“Š Results & Insights

- ğŸŒ² **Random Forest** and ğŸ§  **Neural Network** both perform regression on the **functional coefficients (jfPCs)**.  
- ğŸ” **Permutation Feature Importance (PFI)** reveals the most influential principal components.  
- ğŸŒ€ **Principal Direction (efPC)** plots illustrate how each component deforms the functional curves.  
- ğŸ¯ Outputs include **NMSE**, **RÂ²**, and **Top-15 efPCs** for each model.


